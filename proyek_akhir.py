# -*- coding: utf-8 -*-
"""Proyek_Akhir.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BfUTQMownEGjY6OFSCkQDi-nL7aDS2IG

Nama: Nuril Hidayati

Nomor Registrasi: 1494037162100-621

Pelatihan FGA DTS - Alur Machine Learning Developer

Sidoarjo, Jawa Timur

Dataset : https://www.kaggle.com/trolukovich/apparel-images-dataset?select=black_dress
"""

! pip install kaggle

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download trolukovich/apparel-images-dataset

import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from sklearn.model_selection import train_test_split

print(tf.__version__)

import zipfile,os
local_zip = '/content/apparel-images-dataset.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

pip install split_folders

import splitfolders
base_dir = '/content'
splitfolders.ratio(base_dir, output = '/content/apparel-images-dataset', seed = 1314, ratio = (.8, .2))

train_dir = os.path.join('/content/apparel-images-dataset', 'train')
val_dir = os.path.join('/content/apparel-images-dataset', 'val')

black_dress_dir = os.path.join(base_dir, 'black_dress')
black_pants_dir = os.path.join(base_dir, 'black_pants')
black_shirt_dir = os.path.join(base_dir, 'black_shirt')
black_shoes_dir = os.path.join(base_dir, 'black_shoes')
black_shorts_dir = os.path.join(base_dir, 'black_shorts')
blue_dress_dir = os.path.join(base_dir, 'blue_dress')
blue_pants_dir = os.path.join(base_dir, 'blue_pants')
blue_shirt_dir = os.path.join(base_dir, 'blue_shirt')
blue_shoes_dir = os.path.join(base_dir, 'blue_shoes')
blue_shorts_dir = os.path.join(base_dir, 'blue_shorts')
brown_pants_dir = os.path.join(base_dir, 'brown_pants')
brown_shoes_dir = os.path.join(base_dir, 'brown_shoes')
brown_shorts_dir = os.path.join(base_dir, 'brown_shorts')
green_pants_dir = os.path.join(base_dir, 'green_pants')
green_shirt_dir = os.path.join(base_dir, 'green_shirt')
green_shoes_dir = os.path.join(base_dir, 'green_shoes')
green_shorts_dir = os.path.join(base_dir, 'green_shorts')
red_dress_dir = os.path.join(base_dir, 'red_dress')
red_pants_dir = os.path.join(base_dir, 'red_pants')
red_shoes_dir = os.path.join(base_dir, 'red_shoes')
white_dress_dir = os.path.join(base_dir, 'white_dress')
white_pants_dir = os.path.join(base_dir, 'white_pants')
white_shoes_dir = os.path.join(base_dir, 'white_shoes')
white_shorts_dir = os.path.join(base_dir, 'white_shorts')

train_black_dress_dir, val_black_dress_dir = train_test_split(os.listdir(black_dress_dir), test_size=0.2)
train_black_pants_dir, val_black_pants_dir = train_test_split(os.listdir(black_pants_dir), test_size=0.2)
train_black_shirt_dir, val_black_shirt_dir = train_test_split(os.listdir(black_shirt_dir), test_size=0.2)
train_black_shoes_dir, val_black_shoes_dir = train_test_split(os.listdir(black_shoes_dir), test_size=0.2)
train_black_shorts_dir, val_black_shorts_dir = train_test_split(os.listdir(black_shorts_dir), test_size=0.2)
train_blue_dress_dir, val_blue_dress_dir = train_test_split(os.listdir(blue_dress_dir), test_size=0.2)
train_blue_pants_dir, val_blue_pants_dir = train_test_split(os.listdir(blue_pants_dir), test_size=0.2)
train_blue_shirt_dir, val_blue_shirt_dir = train_test_split(os.listdir(blue_shirt_dir), test_size=0.2)
train_blue_shoes_dir, val_blue_shoes_dir = train_test_split(os.listdir(blue_shoes_dir), test_size=0.2)
train_blue_shorts_dir, val_blue_shorts_dir = train_test_split(os.listdir(blue_shorts_dir), test_size=0.2)
train_brown_pants_dir, val_brown_pants_dir = train_test_split(os.listdir(brown_pants_dir), test_size=0.2)
train_brown_shoes_dir, val_brown_shoes_dir = train_test_split(os.listdir(brown_shoes_dir), test_size=0.2)
train_brown_shorts_dir, val_brown_shorts_dir = train_test_split(os.listdir(brown_shorts_dir), test_size=0.2)
train_green_pants_dir, val_green_pants_dir = train_test_split(os.listdir(green_pants_dir), test_size=0.2)
train_green_shirt_dir, val_green_shirt_dir = train_test_split(os.listdir(green_shirt_dir), test_size=0.2)
train_green_shoes_dir, val_green_shoes_dir = train_test_split(os.listdir(green_shoes_dir), test_size=0.2)
train_green_shorts_dir, val_green_shorts_dir = train_test_split(os.listdir(green_shorts_dir), test_size=0.2)
train_red_dress_dir, val_red_dress_dir = train_test_split(os.listdir(red_dress_dir), test_size=0.2)
train_red_pants_dir, val_red_pants_dir = train_test_split(os.listdir(red_pants_dir), test_size=0.2)
train_red_shoes_dir, val_red_shoes_dir = train_test_split(os.listdir(red_shoes_dir), test_size=0.2)
train_white_dress_dir, val_white_dress_dir = train_test_split(os.listdir(white_dress_dir), test_size=0.2)
train_white_pants_dir, val_white_pants_dir = train_test_split(os.listdir(white_pants_dir), test_size=0.2)
train_white_shoes_dir, val_white_shoes_dir = train_test_split(os.listdir(white_shoes_dir), test_size=0.2)
train_white_shorts_dir, val_white_shorts_dir = train_test_split(os.listdir(white_shorts_dir), test_size=0.2)

train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    validation_split=0.2,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest')
 
test_datagen = ImageDataGenerator(
                    rescale=1./255,
                    validation_split=0.2,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest')

train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(150, 150),
        batch_size=32,
        class_mode='categorical')
 
validation_generator = test_datagen.flow_from_directory(
        val_dir,
        target_size=(150, 150),
        batch_size=32,
        class_mode='categorical')

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(26, activation='softmax')
])

from tensorflow.keras import optimizers
model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

"""**Membuat Class Callback**"""

from tensorflow.keras.callbacks import Callback
class myCallback(Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.92 and logs.get('val_accuracy')>0.92):
      print("\nAkurasi telah mencapai >92%! dan val akurasi telah mencapai >92%!")
      self.model.stop_training = True
callbacks = myCallback()

history = model.fit(
    train_generator,
    steps_per_epoch=25,  
    epochs=100,
    callbacks=[callbacks],
    validation_data=validation_generator, 
    validation_steps=5,
)

model.evaluate(validation_generator)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()),1])
plt.title('Training Accuracy and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
plt.ylim([0,1.0])
plt.title('Training Loss and Validation Loss')
plt.xlabel('epoch')
plt.show()

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(loss, label='Training Loss')
plt.legend(loc='lower right')
plt.ylabel('Training')
plt.ylim([min(plt.ylim()),1])
plt.title('Training Accuracy and Training Loss')

plt.subplot(2, 1, 2)
plt.plot(val_acc, label='Validation Accuracy')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
plt.ylim([0,1.0])
plt.title('Validation Accuracy and Validation Loss')
plt.xlabel('epoch')
plt.show()

# Konversi model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)